---
title: "Probability and Distributions in R"
subtitle: "Foundations of Probability in R"
author: "Seun Odeyemi"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: united
    highlight: tango
    toc: true
    toc_depth: 4
    toc_float: true
---
  
```{r setup}
knitr::opts_chunk$set(error = TRUE, 
                      collapse = TRUE, 
                      comment = "#>")
library(styler)
library(lintr)
library(purrr)
```

# Flipping coins in R

## Simulating coin flips

In these exercises, you'll practice using the `rbinom()` function, which generates random "flips" that are either 1 ("heads") or 0 ("tails").

```{r flipping_1_coin}
# Generate 10 separate random flips with probability .3
args(rbinom)
rbinom(n = 10, size = 1, p = 0.3)
```

`rbinom()` takes three arguments:

* `n` = number of observations i.e. the number of separate random flips
* `size` = number of trials i.e. number of coins
* `p` = probability of success on each trial. 

In this case of a coin flip, `p` is the probability that the coin returns head. Note: if a coin lands on head, we call that a successful trial. 

## Simulating draws from a binomial

In the last exercise, you simulated 10 separate coin flips, each with a 30% chance of heads. Thus, with `rbinom(10, 1, .3)` you ended up with 10 outcomes that were either 0 ("tails") or 1 ("heads").

But by changing the second argument of `rbinom()` (currently `1`), you can flip multiple coins within each draw. Thus, each outcome will end up being a number between *0 and 10*, showing the number of flips that were heads in that trial.

```{r flipping_10_coins}
# Generate 100 occurrences of flipping 10 coins, each with 30% probability
rbinom(n = 100, size = 10, p = 0.3)
```

# Density and cumulative density

When you flip a fair coin 10 times, what's the most likely number of heads? Well, since heads or tails are equally likely, you can probably figure out that the most likely outcome is 5 heads and 5 tails. Say, I offer you a bet if it exactly that result I will pay you a dollar(\$) otherwise you'll pay me a dollar. Should you take the bet? To answer this, we'll have to find out the probability of a binomial random variable `X` with those parameters: 10 flips with a probability of 0.5.

$$X  \sim \textrm{Binomial(10, .5)} $$ 

results in a outcome of 5 which can be expressed as :

$$Pr (X = 5)$$

One way to find out is to simulate many draws from X, say 1000000 and then see how common each outcome is. We can use a neat trick in R to calculate the fraction equal to 5 directly. The expression `flips == 5` compares each item in the vector to 5, we can then use the `mean()` function to find the fraction of comparisons that are `TRUE`. This works because the `mean()` function treats TRUE as 1 and FALSE as 0. Thus, `mean(flips == 5)` gives the fraction of values equals to 5. You're going to be using this trick with mean a lot in the exercises whenever you estimate values with simulation. In this case we found that the fraction of outcomes equals 5 is 0.2450 i.e. there is a 24.5% chance---this is called the density of the binomial at that point. 

```{r plotting_flips, message=FALSE}
# learnr::run_tutorial("introduction", package = "ggformula")
set.seed(10^7*4)
library(ggformula)
flips <- rbinom(100000, 10, .5)
mean(flips == 5) 
gf_histogram( ~ flips, bins = 10, 
              color = "orange", 
              fill = "navy blue", 
              xlab = "Number of heads") + ggtitle("Histogram of simulation: 100000 obs & 10 trials & p = 0.5")
```

Simulation is a very useful to understand a distribution and to answer questions about its behavior. But, in the case of the binomial distribution, R also provides a way to calculate the exact probability density using the `dbinom()` function.

```{r}
dbinom(5, 10, .5)
```

`dbinom()` takes three arguments:

* `d` = the outcome we are estimating the density at, 5. 
* `size` = number of coins, 10
* `p` = probability of each being heads, 0.5. 

Notice, that this gives the result of 0.246. This confirms the result from our simulation of the probability. Similarly, we could calculate the probability density of getting exactly 6 heads or all 10 being heads by changing the first argument. Find the probability through both simulation and exact calculation will be a common task in this course. 

```{r}
dbinom(6, 10, .5)
dbinom(10, 10, .5)
```

So, now you know not to take my bet. More likely than not, we won't exactly 5 heads set of 10. What if I offer you a new bet: I'll pay you a \$ if 4 or fewer come up heads otherwise you have to pay me. 

$$X  \sim \textrm{Binomial(10, .5)} $$ 

results in a outcome equal to or less than 4 which can be expressed as:

$$Pr (X \le 5)$$

This describes the cumulative density of the binomial. The process of calculating the cumulative density is similar to process of calculating the density. You can estimate it using simulation. We generate an 100000 draws from the binomial distribution then instead of using `==` we do `mean(flips <= 4)`. 

```{r}
mean(flips <= 4)
```

You can see that this was true for about 37.8% of the simulations. Much like the density, R provides function to get the exactly cumulatve density of the binomial. Rather than `dbinom()` you use `pbinom()`. 

```{r}
pbinom(4, 10, 0.5)
```

This results confirms the probability is about 37.7% that a binomial with 10 flips gets 4 or fewer heads. In other words, you shouldn't stil take my bet. 

## Calculating density of a binomial

If you flip 10 coins each with a 30% probability of coming up heads, what is the probability exactly 2 of them are heads?

```{r}
# Calculate the probability that 2 are heads using dbinom
dbinom(2, 10, 0.3)

# Confirm your answer with a simulation using rbinom
mean(rbinom(10000, 10, 0.3) == 2)
```

## Calculating cumulative density of a binomial

If you flip ten coins that each have a 30% probability of heads, what is the probability at least five are heads?

```{r}
# Calculate the probability that at least five coins are heads
1 - pbinom(4, 10, 0.3)

# Confirm your answer with a simulation of 10,000 trials
mean(rbinom(10000, 10, 0.3) >= 5)
```

## Varying the number of trials

In the last exercise you tried flipping ten coins with a 30% probability of heads to find the probability at least five are heads. You found that the exact answer was `1 - pbinom(4, 10, .3)` = 0.1502683, then confirmed with 10,000 simulated trials.

Did you need all 10,000 trials to get an accurate answer? Would your answer have been more accurate with more trials?

```{r}
# Here is how you computed the answer in the last problem
# mean(rbinom(10000, 10, .3) >= 5)

# Try now with 100, 1000, 10,000, and 100,000 trials
mean(rbinom(100, 10, .3) >= 5)
mean(rbinom(1000, 10, .3) >= 5)
mean(rbinom(10000, 10, .3) >= 5)
mean(rbinom(100000, 10, .3) >= 5)
```

# Expected value and variance

## Expected value

When we talk about a probability distribution we are often interested in summarizing it into a few descriptive statistics. Two of the most interesting properties of a distribution are where the distribution is centered and how widely spread out it is. We describe this with the *expected value* and the *variance*. The expected value is the mean of the distribution. If you imagine we drew an infinite number of values in the distribution, the expected value is what the average of all those will be. This puts it right in the center of the distribution. 

Let's try to find the expected value of the binomial distribution with `size` (10) and `p` (0.5). We can't draw an infinite number of values, but we can draw a lot of them. We can use `rbinom()` to simulate 100000 draws with size (10) and p (0.5). Then use the `mean()` function to take the average of those draws. We see the average as very close to 5. That's the center of the distribution. 

```{r}
mean(flips)
```

$$X  \sim \textrm{Binomial(size, p)} $$ 

If we try to sample with a size of 100 and p of 0.2, we find that the mean is very close to 20. As you might noticed from these examples, there is a general rule. You can get the expected value of a binomial distribution by multiplying size i.e. the number of flips with p i.e. the probability each is heads:

$$\textrm{E[X] = size . p} $$ 

```{r}
mean(rbinom(100000, 100, 0.2))
```

## Variance

The expected value measures the center of the distribution, but we also want to measure how spread out the results are. Statisticians use the *variance* to measure this. Variance is the average^2^ distance of each value from the mean of the sample. The variance isn't quite as intutive as the mean, but it has useful mathematical properties that will become clear in this course. `R` provides the `var()` function to calculate variance froma particular sample. So we can simulate a 100000 draws of a binomial distribution with size (10) and p (0.5). Then use `var()` to find the variance of that distribution. We that the variance is very close to 2.5. Note: that the mean of this distribution is 5. That means 2.5 is the average^2^ distance between 5 and 1 random draw. 

```{r}
var(rbinom(100000, 10, 0.5))
```

The variance of a binomial distribution follows a particular general rule:

$$Var(X) = \textrm{size . }  p(1 - p) $$ 

So, for example the variance with the binomial parameters of 10 and 0.5 is:

$$Var(X) = \textrm{10 . }  0.5(1 - 0.5) = 2.5$$ 

This is exactly what we saw in the simulation. We could try this with another binomial distribution with size (100) and p(0.2). 

$$Var(X) = \textrm{100 . }  0.2(1 - 0.2) = 16$$ 

```{r}
var(rbinom(100000, 100, 0.2))
```

Just like the expected value, simulation gives us a way to estimate properties of a distribution by drawing many values while mathematical rules can also give you an exact answer. 

We thus have two rules for the properties of a binomial distribution:

1. The expected value of a binomial distribution is $\textrm{E[X] = size . p} $
2. The variance of the binomial distribution is $\textrm{Var(X) = size . p(1 - p)} $

## Calculating the expected value

What is the expected value of a binomial distribution where 25 coins are flipped, each having a 30% chance of heads?

```{r}
# Calculate the expected value using the exact formula
25 * 0.3

# Confirm with a simulation using rbinom
mean(rbinom(10000, 25, 0.3))
```

## Calculating the variance

```{r}
# Calculate the variance using the exact formula
25 * 0.3 * (1 - 0.3)

# Confirm with a simulation using rbinom
var(rbinom(10000, 25, 0.3))
```

# Laws of probability

## Probability of event A and event B
